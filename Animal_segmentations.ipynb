{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Animal_segmentations.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM0WkQUFmrdEcqjAyBPv9v/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/torn2537/PetSegmentation/blob/master/Animal_segmentations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGJRnX9MrIa9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "4088b766-afd7-494a-cd48-5d9372dd5285"
      },
      "source": [
        "!pip install -q -U tfds-nightly\n",
        "!pip install -q git+https://github.com/tensorflow/examples.git\n",
        "#Import tensorflow and check the version.\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for tensorflow-examples (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "2.2.0-rc4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z898uq5_rk8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow_examples.models.pix2pix import pix2pix\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbzYXirbtnNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Specify a dataset's name and load it with tfds.load()\n",
        "dataset_name = 'oxford_iiit_pet:3.*.*'\n",
        "(raw_train, raw_validation, raw_test), metadata = tfds.load(\n",
        "    dataset_name,\n",
        "    split=['train[:80%]', 'train[80%:100%]', 'test'],\n",
        "    with_info=True\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc1o_jqet9q7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4241673-e114-4c4a-d635-6d0fae441d04"
      },
      "source": [
        "print(train)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<ParallelMapDataset shapes: ((128, 128, 3), (128, 128, 1)), types: (tf.float32, tf.float32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nf4Tu7cvEmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Create a normalization function which normalizes images to range [0-255].\n",
        "Moreover, we will 'subtract' masks of images with 1\n",
        "'''\n",
        "def normalize(image, mask_image):\n",
        "  image = tf.cast(image, tf.float32) / 255.0\n",
        "  mask_image = mask_image - 1\n",
        "  return image, mask_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MwCb50rxluf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Create a function named 'loadDataForTraining() with one argument: 'data' \n",
        "and annotate the function with @tf.function to work with TF.\n",
        "In the function, we have to resize the data to be a specific size\n",
        "(Height, Width) For example, resize to be (128,128) and 'augment' the\n",
        "data with various approaches (flip, rotate, etc.)\n",
        "'''\n",
        "@tf.function\n",
        "def loadDataForTraining(data):\n",
        "  size = (128,128)\n",
        "\n",
        "  image = tf.image.resize(data['image'], size)\n",
        "  mask_image = tf.image.resize(data['segmentation_mask'], size)\n",
        "  random_seed = 745\n",
        "  if tf.random.uniform(()) > 0.5:\n",
        "    image = tf.image.random_flip_left_right(image, random_seed)\n",
        "    image = tf.image.random_flip_up_down(image, random_seed)\n",
        "    image = tf.image.random_brightness(image, 0.3, random_seed)\n",
        "    \n",
        "    mask_image = tf.image.random_flip_left_right(mask_image, random_seed)\n",
        "    mask_image = tf.image.random_flip_up_down(mask_image, random_seed)\n",
        "    mask_image = tf.image.random_brightness(mask_image, 0.3, random_seed)\n",
        "\n",
        "  image, mask_image = normalize(image, mask_image)\n",
        "  return image, mask_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7OpLlKM7QF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadDataForTesting(data):\n",
        "  size = (128,128)\n",
        "  image = tf.image.resize(data['image'], size)\n",
        "  mask_image = tf.image.resize(data['segmentation_mask'], size)\n",
        "  image, mask_image = normalize(image, mask_image)\n",
        "  return image, mask_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYeG1iBk8Ubw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_LENGTH = info.splits['train'].num_examples\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 1000\n",
        "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0o2jRnLT-M4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Split each type of data\n",
        "train = raw_train.map(loadDataForTraining, num_parallel_calls=AUTOTUNE)\n",
        "val = raw_validation.map(loadDataForTesting)\n",
        "test = raw_test.map(loadDataForTesting)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}